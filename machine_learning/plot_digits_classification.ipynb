{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognizing hand-written digits\n",
    "\n",
    "An example showing how the scikit-learn can be used to **recognize images of\n",
    "hand-written digits**.\n",
    "\n",
    "http://scikit-learn.org/stable/tutorial/basic/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the **digits** dataset that comes included with scikit-learn. The digits dataset includes a collection of 250 samples of handwritten numbers from 44 writers.\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The digits dataset\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is a dictionary-like object that holds all the data and some metadata about the data. Applicable dataset fields include:\n",
    "- **.target**: ground truth for the dataset\n",
    "- **.data**: raw features\n",
    "- **.images**: array of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[  0.   0.   5.  13.   9.   1.   0.   0.]\n",
      " [  0.   0.  13.  15.  10.  15.   5.   0.]\n",
      " [  0.   3.  15.   2.   0.  11.   8.   0.]\n",
      " [  0.   4.  12.   0.   0.   8.   8.   0.]\n",
      " [  0.   5.   8.   0.   0.   9.   8.   0.]\n",
      " [  0.   4.  11.   0.   1.  12.   7.   0.]\n",
      " [  0.   2.  14.   5.  10.  12.   0.   0.]\n",
      " [  0.   0.   6.  13.  10.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "# View the data array for \"0\"\n",
    "print(digits.target[0])\n",
    "print(digits.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[[  0.   0.   0.  12.  13.   5.   0.   0.]\n",
      " [  0.   0.   0.  11.  16.   9.   0.   0.]\n",
      " [  0.   0.   3.  15.  16.   6.   0.   0.]\n",
      " [  0.   7.  15.  16.  16.   2.   0.   0.]\n",
      " [  0.   0.   1.  16.  16.   3.   0.   0.]\n",
      " [  0.   0.   1.  16.  16.   6.   0.   0.]\n",
      " [  0.   0.   1.  16.  16.   6.   0.   0.]\n",
      " [  0.   0.   0.  11.  16.  10.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "# View the data array for \"1\"\n",
    "print(digits.target[1])\n",
    "print(digits.images[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that we are interested in is made of 8x8 images of digits, let's have a look at the first 8 images, stored in the `images` attribute of the dataset.  If we were working from image files, we could load them using matplotlib.pyplot.imread.  Note that each image must have the same size. For these images, we know which digit they represent: it is given in the 'target' of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADuCAYAAAAZZe3jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSIbgBoBk/hfcRwrybfY3MgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efe4cff07f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:8]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data\n",
    "\n",
    "To apply a classifier on this data, we need to flatten the image, to turn the data in a (samples, feature) matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data in half to get a training set and test set. Only use part of the dataset so that we can evaluate the model's performance with the un-seen values (called test values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_values = data[:n_samples // 2]\n",
    "train_labels = digits.target[:n_samples // 2]\n",
    "\n",
    "test_values = data[n_samples // 2:]\n",
    "test_labels = digits.target[n_samples // 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish the classifier\n",
    "\n",
    "Use the support vector classifier from the support vector machine class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = svm.SVC(gamma=0.001, C=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using only the first half of all available data value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_values, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the classifier\n",
    "\n",
    "Now evaluate the model by predicting the value of the digit on the second half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected = test_labels\n",
    "predicted = classifier.predict(test_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the model's performance values, including a confusion matrix. The higher the precision percent, the better the model is at predicting the digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99        88\n",
      "          1       0.99      0.97      0.98        91\n",
      "          2       0.99      0.99      0.99        86\n",
      "          3       0.98      0.87      0.92        91\n",
      "          4       0.99      0.96      0.97        92\n",
      "          5       0.95      0.97      0.96        91\n",
      "          6       0.99      0.99      0.99        91\n",
      "          7       0.96      0.99      0.97        89\n",
      "          8       0.94      1.00      0.97        88\n",
      "          9       0.93      0.98      0.95        92\n",
      "\n",
      "avg / total       0.97      0.97      0.97       899\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 88  1  0  0  0  0  0  1  1]\n",
      " [ 0  0 85  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 79  0  3  0  4  5  0]\n",
      " [ 0  0  0  0 88  0  0  0  0  4]\n",
      " [ 0  0  0  0  0 88  1  0  0  2]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 88  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 88  0]\n",
      " [ 0  0  0  1  0  1  0  0  0 90]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for classifier:\\n%s\\n\"\n",
    "      % (metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out some test predictions, so we can visualize how the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAB4CAYAAADSWhi9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efe4cdd28d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "    plt.subplot(2, 4, index + 5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
